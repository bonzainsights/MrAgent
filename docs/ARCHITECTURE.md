# ğŸ—ï¸ MRAgent â€” Detailed Architecture Plan

> **Version:** 0.1.0 | **Created:** 2026-02-15 | **Last Updated:** 2026-02-23 | **Status:** Active  
> **Goal:** Build a lightweight Jarvis-like AI agent that runs on low-end hardware using free NVIDIA NIM APIs.

---

## 1. Design Principles

| Principle              | How We Achieve It                                                                                    |
| ---------------------- | ---------------------------------------------------------------------------------------------------- |
| **Lightweight**        | No ML models loaded locally. All inference via API. SQLite for storage. Minimal deps (~15 packages). |
| **Cross-platform**     | Pure Python, no OS-specific deps. Works on Windows/Mac/Linux/old PCs.                                |
| **API-first**          | NVIDIA NIM primary. OpenAI-compatible SDK means easy provider swapping.                              |
| **Privacy-respecting** | All data stored locally. No telemetry. User controls what gets sent to APIs.                         |
| **Modular**            | Each capability (LLM, image, voice, tools) is a swappable plugin.                                    |

---

## 2. System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        USER INTERFACES                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   CLI    â”‚  â”‚  Web (Flask) â”‚  â”‚  Telegram Bot             â”‚  â”‚
â”‚  â”‚  (rich)  â”‚  â”‚  :7860       â”‚  â”‚  (python-telegram-bot)   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                       â–¼                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    AGENT CORE                             â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚  Prompt      â”‚ â”‚  Context   â”‚ â”‚  Model Selector   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  Enhancer    â”‚ â”‚  Manager   â”‚ â”‚  (auto/think/fast)â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â”‚                                                          â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚  Agent Loop: Receive â†’ Plan â†’ Execute â†’ Respond  â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                 â–¼                        â–¼                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚    PROVIDER LAYER     â”‚  â”‚        TOOL SYSTEM             â”‚   â”‚
â”‚  â”‚                       â”‚  â”‚                                â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚  NVIDIA LLM     â”‚ â”‚  â”‚  â”‚ Terminal â”‚ â”‚ File Mgr   â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  (OpenAI SDK)   â”‚ â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚  NVIDIA ImageGenâ”‚ â”‚  â”‚  â”‚ Code Run â”‚ â”‚ Screen Cap â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  (REST API)     â”‚ â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚  NVIDIA TTS     â”‚ â”‚  â”‚  â”‚ Browser  â”‚ â”‚ Web Search â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  (Riva gRPC)    â”‚ â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚  NVIDIA STT     â”‚ â”‚  â”‚  â”‚ PDF Read â”‚ â”‚ Image Gen  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  (Riva gRPC)    â”‚ â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚                 â–¼                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                  MEMORY & STORAGE                         â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚  â”‚  â”‚ Chat Store   â”‚ â”‚ Config       â”‚ â”‚ Chat Summaries   â”‚ â”‚   â”‚
â”‚  â”‚  â”‚ (SQLite)     â”‚ â”‚ Backup/Roll  â”‚ â”‚ & Cross-Ref      â”‚ â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                 â–¼                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                  VOICE PIPELINE                           â”‚   â”‚
â”‚  â”‚  Mic â†’ VAD â†’ STT â†’ Agent â†’ TTS â†’ Speaker                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. NVIDIA NIM API Integration Map

### 3.1 LLM Chat (OpenAI-Compatible REST)

| Model       | NVIDIA NIM ID                         | Use Case                       | Context Window |
| ----------- | ------------------------------------- | ------------------------------ | -------------- |
| Kimi K2.5   | `moonshotai/kimi-k2.5`                | Complex reasoning, agent swarm | 131K           |
| GLM5        | `z-ai/glm5`                           | Reasoning & code, tool calling | 128K           |
| Gemma 3N    | `google/gemma-3n-e4b-it`              | Fast lightweight responses     | 32K            |
| Qwen3 Coder | `qwen/qwen3-coder-480b-a35b-instruct` | Agentic coding, 480B MoE       | 262K           |
| Llama 3.3   | `meta/llama-3.3-70b-instruct`         | General fallback               | 128K           |

**Endpoint:** `https://integrate.api.nvidia.com/v1/chat/completions`  
**Auth:** Bearer token from env  
**SDK:** `openai` Python package (set `base_url` to NVIDIA)

```python
from openai import OpenAI

client = OpenAI(
    base_url="https://integrate.api.nvidia.com/v1",
    api_key=os.environ["NVIDIA_KIMI_K2_5"]
)

# Standard chat completion
response = client.chat.completions.create(
    model="moonshotai/kimi-k2.5",
    messages=[{"role": "user", "content": "Hello MRAgent!"}],
    temperature=0.7,
    max_tokens=1024,
    stream=True
)

# Function calling (tool use)
response = client.chat.completions.create(
    model="moonshotai/kimi-k2.5",
    messages=messages,
    tools=[{
        "type": "function",
        "function": {
            "name": "execute_terminal",
            "description": "Run a shell command",
            "parameters": {
                "type": "object",
                "properties": {
                    "command": {"type": "string", "description": "Shell command to execute"}
                },
                "required": ["command"]
            }
        }
    }],
    tool_choice="auto"
)
```

### 3.2 Image Generation (REST API)

**Stable Diffusion 3.5 Large:**

```
POST https://ai.api.nvidia.com/v1/genai/stabilityai/stable-diffusion-3-5-large
Authorization: Bearer {NVIDIA_SD_35_LARGE}
Content-Type: application/json

{
    "text_prompts": [{"text": "A cyberpunk city at sunset", "weight": 1}],
    "cfg_scale": 5,
    "height": 1024,
    "width": 1024,
    "steps": 50,
    "seed": 0
}
â†’ Response: {"artifacts": [{"base64": "...", "seed": 12345}]}
```

**FLUX Dev:**

```
POST https://ai.api.nvidia.com/v1/genai/black-forest-labs/flux.1-dev
Same auth/format pattern
```

### 3.3 Text-to-Speech (Riva gRPC)

```python
import riva.client

auth = riva.client.Auth(
    uri="grpc.nvcf.nvidia.com:443",
    use_ssl=True,
    metadata_args=[
        ["function-id", "0149dedb-2be8-4195-b9a0-e57e0e14f972"],
        ["authorization", f"Bearer {os.environ['NVIDIA_MAGPIE_TTS']}"]
    ]
)

tts = riva.client.SpeechSynthesisService(auth)
resp = tts.synthesize(
    text="Hello, I am MRAgent!",
    voice_name="English-US.Female-1",
    language_code="en-US",
    encoding=riva.client.AudioEncoding.LINEAR_PCM,
    sample_rate_hz=44100
)
# resp.audio â†’ raw PCM bytes, play via sounddevice
```

### 3.4 Speech-to-Text (Riva gRPC)

```python
asr = riva.client.ASRService(auth_whisper)
config = riva.client.StreamingRecognitionConfig(
    config=riva.client.RecognitionConfig(
        encoding=riva.client.AudioEncoding.LINEAR_PCM,
        language_code="en-US",
        max_alternatives=1,
        enable_automatic_punctuation=True,
        sample_rate_hertz=16000,
    ),
    interim_results=True,
)
# Stream microphone audio â†’ get real-time transcriptions
```

### 3.5 Brave Search (REST)

```python
response = requests.get(
    "https://api.search.brave.com/res/v1/web/search",
    headers={"X-Subscription-Token": os.environ["BRAVE_SEARCH_API_KEY"]},
    params={"q": query, "count": 5, "safesearch": "moderate"}
)
results = response.json()["web"]["results"]
# Extract: title, url, description for each result
```

---

## 4. Agent Core â€” The Brain

### 4.1 Main Loop (ReAct Pattern)

```
User Input
    â”‚
    â–¼
â”Œâ”€ ENHANCE PROMPT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  - Add system prompt (identity, time)  â”‚
â”‚  - Add context (OS, cwd, open files)   â”‚
â”‚  - Rewrite vague queries               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â–¼
â”Œâ”€ SELECT MODEL â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  auto: classify â†’ fast/think/code     â”‚
â”‚  manual: user-selected model          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â–¼
â”Œâ”€ LLM CALL (with tools) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Send messages + tool definitions      â”‚
â”‚  Get response (text or tool_calls)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â–¼
     â”Œâ”€ Has tool_calls? â”€â”
     â”‚                    â”‚
    YES                  NO
     â”‚                    â”‚
     â–¼                    â–¼
â”Œâ”€ EXECUTE TOOLS â”€â”€â”  â”Œâ”€ OUTPUT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Run each tool    â”‚  â”‚  Display text     â”‚
â”‚  Format results   â”‚  â”‚  or TTS playback  â”‚
â”‚  Append to msgs   â”‚  â”‚  Save to history  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â””â”€â”€â–º Loop back to LLM CALL
```

### 4.2 Context Management Strategy

```
Max Context: ~128K tokens (Kimi K2.5)

Active Window:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ System Prompt           (~500)  â”‚
â”‚ Context Injection       (~200)  â”‚
â”‚ Chat Summary (if any)   (~500)  â”‚
â”‚ Recent Messages     (~100,000)  â”‚
â”‚ Tool Results            (~var)  â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Buffer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ Reserved for Response  (~8,000) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

When context reaches 80%:
1. Summarize oldest messages â†’ store summary
2. Replace old messages with summary
3. Keep last 10 messages in full
4. Full history always in SQLite

Auto New Chat:
- When summary quality degrades (topic drift detected)
- User can force: /newchat
- Previous chat accessible via /history
```

### 4.3 Model Auto-Selection Logic

```python
def select_model(user_message: str, mode: str = "auto") -> str:
    if mode == "thinking":
        return "moonshotai/kimi-k2.5"  # Best reasoning
    elif mode == "fast":
        return "google/gemma-3n-e4b-it"  # Fastest

    # Auto mode: classify the task
    keywords_code = ["code", "function", "bug", "implement", "debug", "script"]
    keywords_complex = ["analyze", "plan", "design", "compare", "explain why"]

    msg_lower = user_message.lower()
    if any(k in msg_lower for k in keywords_code):
        return "qwen/qwen3-coder-480b-a35b-instruct"
    elif any(k in msg_lower for k in keywords_complex):
        return "moonshotai/kimi-k2.5"
    else:
        return "meta/llama-3.3-70b-instruct"
```

---

## 5. Memory Architecture

### 5.1 SQLite Schema

```sql
-- Lightweight: one file, no server, <1MB for 10K messages
CREATE TABLE chats (
    id TEXT PRIMARY KEY,     -- UUID
    title TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    summary TEXT,            -- Auto-generated summary
    token_count INTEGER DEFAULT 0
);

CREATE TABLE messages (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    chat_id TEXT REFERENCES chats(id),
    role TEXT,               -- system/user/assistant/tool
    content TEXT,
    tool_calls TEXT,         -- JSON if assistant made tool calls
    tool_call_id TEXT,       -- if this is a tool result
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    token_estimate INTEGER
);

CREATE TABLE config_snapshots (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    snapshot BLOB,           -- JSON of full config
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
-- Keep only last 3 rows via trigger
```

### 5.2 Config Backup/Rollback

```
data/
â”œâ”€â”€ chats.db              # SQLite database
â”œâ”€â”€ config_backups/
â”‚   â”œâ”€â”€ config_001.json   # 3 steps ago
â”‚   â”œâ”€â”€ config_002.json   # 2 steps ago
â”‚   â””â”€â”€ config_003.json   # most recent
â”œâ”€â”€ images/               # Generated images
â””â”€â”€ logs/
    â””â”€â”€ mragent.log       # Rotating log file
```

---

## 6. Kimi K2.5 Agent Swarm

Kimi K2.5's unique capability: coordinate up to 100 sub-agents with 1,500 tool calls per session.

### How We Use It:

```
User: "Create me a portfolio website"
          â”‚
          â–¼
â”Œâ”€ ORCHESTRATOR (Kimi K2.5) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Decompose task into sub-tasks:      â”‚
â”‚  1. Plan site structure              â”‚
â”‚  2. Generate content                 â”‚
â”‚  3. Write HTML/CSS                   â”‚
â”‚  4. Create images                    â”‚
â”‚  5. Review & fix                     â”‚
â”‚                                      â”‚
â”‚  For each sub-task â†’ tool calls:     â”‚
â”‚  - file_write("index.html", ...)     â”‚
â”‚  - file_write("styles.css", ...)     â”‚
â”‚  - generate_image("hero banner")     â”‚
â”‚  - terminal("python -m http.server") â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

The swarm works through Kimi's **native multi-step tool calling** â€” no separate swarm framework needed. We just provide all tools and let Kimi orchestrate.

---

## 7. Directory Structure (Final)

```
MRAgent/
â”œâ”€â”€ main.py                    # Entry point & startup
â”œâ”€â”€ requirements.txt           # Dependencies
â”œâ”€â”€ .env                       # API keys (gitignored)
â”œâ”€â”€ .env.example               # Template
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py            # Config, model registry, autonomy settings
â”‚
â”œâ”€â”€ providers/
â”‚   â”œâ”€â”€ base.py                # Abstract provider interface
â”‚   â”œâ”€â”€ nvidia_llm.py          # NVIDIA LLM (OpenAI SDK)
â”‚   â”œâ”€â”€ nvidia_image.py        # NVIDIA Image Gen (REST)
â”‚   â”œâ”€â”€ tts.py                 # Edge TTS
â”‚   â”œâ”€â”€ nvidia_stt.py          # Groq STT
â”‚   â”œâ”€â”€ brave_search.py        # Brave Search API
â”‚   â”œâ”€â”€ google_search.py       # Google Custom Search API
â”‚   â””â”€â”€ langsearch.py          # LangSearch API
â”‚
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ core.py                # Main agent loop + tiered approval
â”‚   â”œâ”€â”€ prompt_enhancer.py     # Prompt rewriting & context injection
â”‚   â”œâ”€â”€ context_manager.py     # Token counting & sliding window
â”‚   â”œâ”€â”€ model_selector.py      # Auto model selection
â”‚   â””â”€â”€ watcher.py             # Eagle Eye screen monitor
â”‚
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ base.py                # Base tool interface + OpenAI schema
â”‚   â”œâ”€â”€ terminal.py            # Shell command execution
â”‚   â”œâ”€â”€ file_manager.py        # File operations
â”‚   â”œâ”€â”€ code_runner.py         # Code execution sandbox
â”‚   â”œâ”€â”€ screen.py              # Screen capture & diff
â”‚   â”œâ”€â”€ browser.py             # Web fetch & search (with sanitizer)
â”‚   â”œâ”€â”€ pdf_reader.py          # PDF text extraction
â”‚   â””â”€â”€ image_gen.py           # Image generation tool
â”‚
â”œâ”€â”€ skills/
â”‚   â”œâ”€â”€ agentmail.py           # Email skill
â”‚   â””â”€â”€ telegram.py            # Telegram skill
â”‚
â”œâ”€â”€ memory/
â”‚   â””â”€â”€ chat_store.py          # SQLite chat storage
â”‚
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ cli.py                 # Rich CLI (commands, menus, autonomy)
â”‚   â”œâ”€â”€ web.py                 # Flask browser interface
â”‚   â””â”€â”€ telegram_bot.py        # Telegram bot
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ sanitizer.py           # Prompt injection defense
â”‚   â”œâ”€â”€ logger.py              # Logging system
â”‚   â””â”€â”€ helpers.py             # Shared utilities
â”‚
â”œâ”€â”€ core/
â”‚   â””â”€â”€ poneglyph.py           # System Guardian & Doctor
â”‚
â”œâ”€â”€ data/                      # Runtime data (gitignored)
â”‚   â”œâ”€â”€ chats.db
â”‚   â”œâ”€â”€ config_backups/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ logs/
â”‚
â””â”€â”€ docs/
    â””â”€â”€ ARCHITECTURE.md        # This file
```

---

## 8. Dependency Budget

Target: **< 50MB installed** (excluding pip cache)

| Package               | Size   | Purpose                            |
| --------------------- | ------ | ---------------------------------- |
| `openai`              | ~5MB   | LLM API client (OpenAI-compatible) |
| `nvidia-riva-client`  | ~30MB  | gRPC client for TTS/STT            |
| `requests`            | ~0.5MB | HTTP client for REST APIs          |
| `python-dotenv`       | ~0.1MB | .env file loading                  |
| `rich`                | ~3MB   | Terminal UI                        |
| `prompt-toolkit`      | ~2MB   | Interactive CLI input              |
| `Pillow`              | ~5MB   | Image handling                     |
| `sounddevice`         | ~0.5MB | Audio capture/playback             |
| `numpy`               | ~15MB  | Audio array handling               |
| `flask`               | ~1MB   | Web server (optional)              |
| `pyautogui`           | ~1MB   | Screen capture                     |
| `beautifulsoup4`      | ~0.5MB | HTML parsing                       |
| `python-telegram-bot` | ~1MB   | Telegram interface (optional)      |

**Total: ~66MB** (acceptable for low-end devices, no GPU needed)

---

## 9. Rate Limit Strategy

NVIDIA NIM free tier: ~40 requests/min

```python
class RateLimiter:
    def __init__(self, max_rpm=35):  # Leave 5 RPM headroom
        self.max_rpm = max_rpm
        self.requests = []  # Timestamps of recent requests

    def wait_if_needed(self):
        now = time.time()
        self.requests = [t for t in self.requests if now - t < 60]
        if len(self.requests) >= self.max_rpm:
            sleep_time = 60 - (now - self.requests[0])
            time.sleep(sleep_time)
        self.requests.append(time.time())
```

---

## 10. Implementation Phases & Timeline

| Phase        | What                                                 | Estimated Effort |
| ------------ | ---------------------------------------------------- | ---------------- |
| **Phase 2**  | Core foundation (config, logging, main.py)           | ~2 hours         |
| **Phase 3**  | Provider layer (NVIDIA LLM, image, TTS, STT, search) | ~4 hours         |
| **Phase 4**  | Tool system (terminal, files, code, screen, browser) | ~3 hours         |
| **Phase 5**  | Agent core (loop, prompt enhancer, context manager)  | ~4 hours         |
| **Phase 6**  | Memory & history (SQLite, config backup)             | ~2 hours         |
| **Phase 7**  | Voice pipeline (mic â†’ STT â†’ agent â†’ TTS)             | ~3 hours         |
| **Phase 8**  | User interfaces (CLI, web, Telegram)                 | ~4 hours         |
| **Phase 9**  | Advanced features (swarm, screen monitor, planning)  | ~4 hours         |
| **Phase 10** | Testing & polish                                     | ~3 hours         |

**Total: ~29 hours of focused implementation**

---

## 11. Security & Autonomy Architecture

### 11.1 Prompt Injection Defense (2-Layer)

```
External Data (web pages, search results, PDFs)
    â”‚
    â–¼
â”Œâ”€ LAYER 1: Sanitizer (utils/sanitizer.py) â”€â”€â”€â”€â”
â”‚  1. strip_dangerous_patterns()                 â”‚
â”‚     - Regex detection of injection patterns    â”‚
â”‚     - Removes: "ignore instructions",          â”‚
â”‚       "share API keys", embedded bash/python   â”‚
â”‚  2. sanitize_external_data()                   â”‚
â”‚     - Wraps in structural markers:             â”‚
â”‚     â•â•â• [UNTRUSTED EXTERNAL DATA] â•â•â•          â”‚
â”‚     ... content ...                            â”‚
â”‚     â•â•â• [END UNTRUSTED EXTERNAL DATA] â•â•â•      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€ LAYER 2: System Prompt (prompt_enhancer.py) â”€â”
â”‚  - LLM instructed to NEVER follow             â”‚
â”‚    instructions inside UNTRUSTED markers       â”‚
â”‚  - Data treated as DISPLAY-ONLY               â”‚
â”‚  - Report injection attempts to user           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 11.2 Tiered Approval System

```
Tool Call (execute_terminal / run_code)
    â”‚
    â–¼
â”Œâ”€ Check AUTONOMY_SETTINGS.trust_level â”€â”
â”‚                                        â”‚
â”œâ”€â”€ "autonomous" â”€â”€â–º Run immediately     â”‚
â”‚                    Log action           â”‚
â”‚                                        â”‚
â”œâ”€â”€ "balanced" â”€â”€â”€â”€â–º Check patterns:     â”‚
â”‚   â”‚ is_safe_command() OR               â”‚
â”‚   â”‚ fnmatch(cmd, auto_approve_patterns)â”‚
â”‚   â”œâ”€â”€ Match â”€â”€â–º Auto-run               â”‚
â”‚   â””â”€â”€ No match â”€â”€â–º Ask user            â”‚
â”‚                    + Telegram notify    â”‚
â”‚                                        â”‚
â”œâ”€â”€ "cautious" â”€â”€â”€â”€â–º Always ask user     â”‚
â”‚                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

_This document will be updated as implementation progresses. Each phase will be committed separately with detailed logging._
